{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python main.py minimum_support_count_threshold min_confidence data_file_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gururajan\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Author: Manohar Mukku\n",
    "# Date: 23.08.2018\n",
    "# Desc: Apriori Algorithm to find frequent itemsets\n",
    "# Link: https://github.com/manoharmukku/data-mining-projects/apriori\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def find_frequent_1_itemsets(data, min_sup):\n",
    "    # Generate Candidate 1-itemsets\n",
    "    C0 = {}\n",
    "    for transaction in data:\n",
    "        for item in transaction:\n",
    "            if (item in C0):\n",
    "                C0[item] += 1\n",
    "            else:\n",
    "                C0[item] = 1\n",
    "\n",
    "    # Find the frequent 1-itemsets\n",
    "    L0 = []\n",
    "    for key, value in C0.items():\n",
    "        if (value >= min_sup):\n",
    "            L0.append([[key], value])\n",
    "\n",
    "    # Return the frequent 1-itemset\n",
    "    return sorted(L0)\n",
    "\n",
    "def find_frequent_k_itemsets(Ck, data, min_sup):\n",
    "    # Get the counts of itemsets in Ck\n",
    "    Ck_dict = {}\n",
    "    for i in range(len(Ck)):\n",
    "        for transaction in data:\n",
    "            if (set(Ck[i]) <= set(transaction)):\n",
    "                if (tuple(Ck[i]) in Ck_dict):\n",
    "                    Ck_dict[tuple(Ck[i])] += 1\n",
    "                else:\n",
    "                    Ck_dict[tuple(Ck[i])] = 1\n",
    "\n",
    "    # Find the frequent itemsests in Ck\n",
    "    Lk = []\n",
    "    for key, value in Ck_dict.items():\n",
    "        if (value >= min_sup):\n",
    "            Lk.append([list(key), value])\n",
    "\n",
    "    # Return the sorted frequent k-itemset\n",
    "    return sorted(Lk)\n",
    "\n",
    "def check_and_join(l1, l2):\n",
    "    c = []\n",
    "    k = len(l1)\n",
    "\n",
    "    if (k == 1):\n",
    "        c.extend(l1)\n",
    "        c.extend(l2)\n",
    "        return c\n",
    "\n",
    "    flag = True\n",
    "    for i in range(k-1):\n",
    "        if (l1[i] != l2[i]):\n",
    "            flag = False\n",
    "            break\n",
    "\n",
    "    if (flag):\n",
    "        c.extend(l1[0:k-2])\n",
    "\n",
    "        if (l1[k-1] < l2[k-1]):\n",
    "            c.extend(l1[k-1])\n",
    "            c.extend(l2[k-1])\n",
    "        else:\n",
    "            c.extend(l2[k-1])\n",
    "            c.extend(l1[k-1])\n",
    "\n",
    "    return c\n",
    "\n",
    "def has_infrequent_subset(c, l_prev):\n",
    "    # Create a dictionary of l_prev\n",
    "    l_prev_dict = {}\n",
    "    for i in range(len(l_prev)):\n",
    "        l_prev_dict[tuple(l_prev[i][0])] = 1\n",
    "\n",
    "    # Iterate over all subsets of c and check whether they are all present in l_prev\n",
    "    k = len(l_prev[0][0])\n",
    "    for subset in itertools.combinations(c, k):\n",
    "        if (subset not in l_prev_dict):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def apriori_gen(l_prev):\n",
    "    # Construct candidate k-itemset, Ck by joining and pruning itemsets in l_prev\n",
    "    Ck = []\n",
    "    for i in range(len(l_prev)-1):\n",
    "        for j in range(i+1, len(l_prev)):\n",
    "            c = check_and_join(l_prev[i][0], l_prev[j][0])\n",
    "            if (len(c) > 0 and has_infrequent_subset(c, l_prev) == False):\n",
    "                Ck.append(c)\n",
    "\n",
    "    return Ck\n",
    "\n",
    "# Sanity check of command line arguments\n",
    "if (len(sys.argv) != 4):\n",
    "    print (\"Usage: python main.py minimum_support_count_threshold min_confidence data_file_path\")\n",
    "    sys.exit()\n",
    "\n",
    "# Mimimum support count threshold\n",
    "min_sup = int(sys.argv[1])\n",
    "if (min_sup <= 0):\n",
    "    print (\"Error: Minimum support count value should be positive\")\n",
    "    sys.exit()\n",
    "\n",
    "min_conf = int(sys.argv[2])\n",
    "if (min_conf <= 0):\n",
    "    print (\"Error: Minimum confidence value should be positive\")\n",
    "    sys.exit()\n",
    "\n",
    "# Read the csv data file to a pandas dataframe\n",
    "df = pd.read_csv(sys.argv[3], header=None, names=['List of items'])\n",
    "\n",
    "# Store the dataframe as a list of lists\n",
    "data = []\n",
    "for _, row in df.iterrows():\n",
    "    data.append(sorted(row['List of items'].split(\",\")))\n",
    "\n",
    "# Find frequent 1-itemsets\n",
    "L0 = find_frequent_1_itemsets(data, min_sup)\n",
    "\n",
    "# Append L0 to the final frequent itemsets list\n",
    "L = []\n",
    "L.append(L0)\n",
    "\n",
    "# Iterate on k to find frequent k-itemsets\n",
    "k = 1\n",
    "while (len(L[k-1]) > 0):\n",
    "    Ck = apriori_gen(L[k-1])\n",
    "    Lk = find_frequent_k_itemsets(Ck, data, min_sup)\n",
    "    L.append(Lk)\n",
    "    k += 1\n",
    "\n",
    "# Print the frequent itemsets\n",
    "print ('{:30}{:15}'.format('Frequent Itemset', 'Support Count'))\n",
    "print (\"--------------------------------------------\")\n",
    "for freq_itemset in L:\n",
    "    for itemset in freq_itemset:\n",
    "        print ('{:30}{:5}'.format(str(itemset[0]), itemset[1]))\n",
    "\n",
    "# Store the support counts in dictionary\n",
    "sup_count = {}\n",
    "for freq_itemset in L:\n",
    "    for itemset in freq_itemset:\n",
    "        sup_count[tuple(itemset[0])] = itemset[1]\n",
    "\n",
    "# Find and print the association rules\n",
    "print (\"\\nAssociation rules:\")\n",
    "print (\"--------------------\")\n",
    "for freq_itemset in L:\n",
    "    for itemset in freq_itemset:\n",
    "        if (len(itemset[0]) <= 1):\n",
    "            continue\n",
    "\n",
    "        # Generate all the subsets of the current itemset\n",
    "        for i in range(1,len(itemset[0])):\n",
    "            for subset in itertools.combinations(itemset[0], i):\n",
    "                # Check the association rule confidence\n",
    "                if ((sup_count[subset] / sup_count[tuple(sorted(set(itemset[0]) - set(subset)))]) >= min_conf):\n",
    "                    print (subset,' => ', tuple(sorted(set(itemset[0]) - set(subset))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
